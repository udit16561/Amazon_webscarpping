{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CanCehC9Gkli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "13rvmfZpLAbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785c7fed-f287-4c3a-9408-927c21ddca3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl beautifulsoup4 lxml\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to parse the HTML and extract data\n",
        "def parse_amazon_html(file_path):\n",
        "    try:\n",
        "        # Read the HTML file\n",
        "        with open(file_path, \"r\", encoding=\"utf8\") as file:\n",
        "            content = file.read()\n",
        "\n",
        "        # Create a BeautifulSoup object\n",
        "        soup = BeautifulSoup(content, \"lxml\")\n",
        "\n",
        "        # Extract the name\n",
        "        try:\n",
        "            name = soup.findAll(\"span\", class_=\"a-size-medium a-color-base a-text-normal\").get_text().strip()\n",
        "        except AttributeError:\n",
        "            name = \"\"\n",
        "\n",
        "        # Extract the price\n",
        "        try:\n",
        "            price = soup.findAll(\"span\", class_=\"a-price-whole\").get_text().strip()\n",
        "        except AttributeError:\n",
        "            price = \"\"\n",
        "\n",
        "        # Extract the review\n",
        "        try:\n",
        "            review = soup.findAll(\"span\", class_=\"a-icon-alt\").get_text().strip()\n",
        "        except AttributeError:\n",
        "            review = \"\"\n",
        "\n",
        "        return name, price, review\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing file: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# Function to write data to Excel\n",
        "def write_to_excel(data, output_file):\n",
        "    # Create a new Excel workbook and select the active sheet\n",
        "    wb = openpyxl.Workbook()\n",
        "    ws = wb.active\n",
        "    ws.title = \"Amazon Products\"\n",
        "\n",
        "    # Write headers\n",
        "    ws.append([\"Name\", \"Price\", \"Reviews\"])\n",
        "\n",
        "    # Write data\n",
        "    for entry in data:\n",
        "        ws.append(entry)\n",
        "\n",
        "    # Save the Excel file\n",
        "    wb.save(output_file)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Path to the amazon.html file\n",
        "    html_file = \"/content/Amazon.html\"\n",
        "\n",
        "    # Parse the HTML file and extract data\n",
        "    name, price, review = parse_amazon_html(html_file)\n",
        "\n",
        "    # If data is successfully extracted, write it to an Excel file\n",
        "    if name or price or review:\n",
        "        data = [(name, price, review)]\n",
        "        output_file = \"amazon_products.xlsx\"\n",
        "        write_to_excel(data, output_file)\n",
        "        print(f\"Data successfully written to {output_file}\")\n",
        "    else:\n",
        "        print(\"No data found.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "uIZ_0jUdHg6y",
        "outputId": "88132e09-0836-45af-f282-3b3157bff480"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (<ipython-input-13-100329f3e59a>, line 16)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-100329f3e59a>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    name = soup.findAll([\"span\", class_=\"a-size-medium a-color-base a-text-normal\"]).get_text().strip()\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to parse the HTML and extract data\n",
        "def parse_amazon_html(file_path):\n",
        "    try:\n",
        "        # Read the HTML file\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            content = file.read()\n",
        "\n",
        "        # Create a BeautifulSoup object\n",
        "        soup = BeautifulSoup(content, \"lxml\")\n",
        "\n",
        "        # Extract all product names\n",
        "        try:\n",
        "            names = [name.get_text().strip() for name in soup.find_all(\"span\", class_=\"a-size-medium a-color-base a-text-normal\")]\n",
        "        except AttributeError:\n",
        "            names = [\"\"]\n",
        "\n",
        "        # Extract all prices\n",
        "        try:\n",
        "            prices = [price.get_text().strip() for price in soup.find_all(\"span\", class_=\"a-price-whole\")]\n",
        "        except AttributeError:\n",
        "            prices = [\"\"]\n",
        "\n",
        "        # Extract all reviews\n",
        "        try:\n",
        "            reviews = [review.get_text().strip() for review in soup.find_all(\"span\", class_=\"a-icon-alt\")]\n",
        "        except AttributeError:\n",
        "            reviews = [\"\"]\n",
        "\n",
        "        return names, prices, reviews\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing file: {e}\")\n",
        "        return [], [], []\n",
        "\n",
        "# Function to write data to Excel\n",
        "def write_to_excel(names, prices, reviews, output_file):\n",
        "    # Create a new Excel workbook and select the active sheet\n",
        "    wb = openpyxl.Workbook()\n",
        "    ws = wb.active\n",
        "    ws.title = \"Amazon Products\"\n",
        "\n",
        "    # Write headers\n",
        "    ws.append([\"Name\", \"Price\", \"Reviews\"])\n",
        "\n",
        "    # Write data row by row\n",
        "    for name, price, review in zip(names, prices, reviews):\n",
        "        ws.append([name, price, review])\n",
        "\n",
        "    # Save the Excel file\n",
        "    wb.save(output_file)\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Path to the amazon.html file\n",
        "    html_file = \"/content/Amazon.html\"\n",
        "\n",
        "    # Parse the HTML file and extract data\n",
        "    names, prices, reviews = parse_amazon_html(html_file)\n",
        "\n",
        "    # If data is successfully extracted, write it to an Excel file\n",
        "    if names or prices or reviews:\n",
        "        output_file = \"amazon_products.xlsx\"\n",
        "        write_to_excel(names, prices, reviews, output_file)\n",
        "        print(f\"Data successfully written to {output_file}\")\n",
        "    else:\n",
        "        print(\"No data found.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "wsWXZwCUvIfz",
        "outputId": "80caad52-fae5-4893-9514-1c57d8f72109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully written to amazon_products.xlsx\n"
          ]
        }
      ]
    }
  ]
}